\documentclass[../AP_Statistics.tex]{subfiles}

\begin{document}
	\chapter{Confidence Intervals}
	\chapter{Significance Tests}
		A \textbf{significance test} is a procedure that uses observed data to test between two claims, often made regarding parameters, about hypotheses. \\
		The \textbf{null hypothesis} ($\pmb{H_0}$) claims that the parameter is equal to a \textbf{null value}, what it was previously assumed to be, denoted by a subscript $0$ on the parameter. It is often a statement of no change or difference.
		$$H_0:\rm{parameter} < \text{null value}$$
		The claim that is attempting to be supported is the \textbf{alternative hypothesis} ($\pmb{H_a}$). It can either be \textbf{one-sided}, claiming that the parameter is greater or less than the null value, or \textbf{two-sided}, claiming simply that the parameter is not equal to the null value.
		$$H_a:\rm{parameter} \gtrless \text{null value} \lor \rm{parameter} \ne \text{null value}$$
		A test's $\pmb{P}$\textbf{-value} is the probability of evidence being found for $H_a$ that is at least as strong as it would be assuming that $H_0$ is true.
		$$P\text{-value} = P(\text{statistic supports } H_a \mid H_0)$$ \\
		The smaller the $P$-value, the lower the chances of receiving evidence of the alternative. A small $P$-value therefore supports the $H_a$. \\
		If the $P$-value is less than the \textbf{significance level} $\pmb{\alpha}$, $H_0$ can be rejected and it can be concluded that there is convincing evidence for $H_a$. If the $P$-value is greater than or equal to $\alpha$, $H_0$ cannot be rejected, and it can be concluded that there is not convincing evidence for $H_a$. \\
		The $P$-value is calculated using the \textbf{standardized test statistic} $z$, which is equal to the $z$ score of the the sample statistic assuming the null hypothesis is true.
		$$z = \z{\text{statistic}}{\text{null parameter}}{\text{standard error of statistic from null parameter}}$$
		The $P$-value is equal to the probability of $z$ satisfying the $H_a$ assuming that $H_0$ is true. It can therefore be calculated as such, so long as Normality and independence are justified.
		$$\small
			P\text{-value} = \begin{cases}
				P(\text{parameter} \gtrless \text{null parameter}) = P(Z \gtrless z) & H_a:\text{parameter} \gtrless \text{null parameter} \\
				P(|\text{parameter}| < |\text{null parameter}|) = P(Z < -|z|) + P(Z > |z|) & H_a:\text{parameter} \ne \text{null parameter}
			\end{cases}
		$$
		\callout{17}{Conclusions should only ever be made regarding the rejection of $H_0$ and the convincing support of $H_a$. $H_0$ should never be supported and $H_a$ should never be rejected.}
		When performing significance tests, two types of errors may occur:
		\begin{itemize}
			\item
				A \textbf{Type \Roman{1} error} occurs when $H_0$ is rejected despite $H_a$ being false; the data provided convincing evidence for $H_a$ despite it being incorrect. 
			\item
			A \textbf{Type \Roman{2} error} occurs when $H_0$ is not rejected despite $H_a$ being true; the data did not provide convincing evidence for $H_a$ despite it being correct.
		\end{itemize}
		The probability of a Type \Roman{1} error occurring is equal to $\alpha$. \\
		As $\alpha$ increases, the probability of a Type \Roman{1} error increases but that of a Type \Roman{2} error decreases.
		A confidence interval can be used in tandem with a sample statistic to provide a set of plausible values for the true parameter, should the alternative hypothesis be convincingly supported. \\
		A two-sided test of of $H_0$ at significance level $\alpha$ usually provides the same conclusion as a confidence level of the complement of $\alpha$.
		$$[P(Z < z) < \alpha] \approxident [\text{null parameter} \in (\text{statistic} \pm ME)]$$
		A test's \textbf{power} is the probability of convincing evidence being found that convincingly supports $H_a$ given a value for the parameter being tested. This is also is equal to the probability of avoiding a Type \Roman{2} error. 
		$$\mathrm{power} = 1 - P(\text{Type \Roman{2} Error})^C = P(\text{statistic convincingly supports } H_a \mid H_a \text{ is true})$$
		Power can be increased in three ways:
		\begin{enumerate}
			\item Increasing the sample size
				\begin{itemize}
					\item A large sample means that more data is collected and more information is given regarding the true population parameter. This also increases $n$, which decreases $s$, reducing $z$ and therefore the $P$-value, making it more likely to fall below $\alpha$.
				\end{itemize}
			\item Increasing the significance level
				\begin{itemize}
					\item Increasing the significance level increases the probability of $H_0$ being rejected when $H_a$ is true, as the maximum $P$-value for $H_0$ to be rejected increases.
				\end{itemize}
			\item Increasing the \textbf{effect size}, the minimum difference between the null parameter value and the alternative parameter value for the change to matter
				\begin{itemize}
					\item Increasing the size of the difference that needs to be detected makes that difference more likely to be detected, as larger differences are easier to detect.
				\end{itemize}
		\end{enumerate}
		\section*{Significance Tests about Proportions}
			\callout{17}{In order for a significance test of $H_0:p = p_0$ to be performed, it must be verified that the distribution of $\hat{p}$ is approximately Normal assuming $H_0$ and that the standard error can be calculated, so Large Counts and the 10\% condition (not for experiments) must be satisfied and interpreted for Normality and independence respectively.}
			To perform a significance test about a proportion $z$ must be calculated. \\
			$$z = \frac{\hat{p} - \mu_{\hat{p}_0}}{s_{p_0}} = \frac{\hat{p} - p_0}{\sqrt{\frac{p_0(1 - p_0)}{n}}}$$
			The $P$-value is the probability of $p$ satisfying $H_a$ when $H_0$ is true, which can be calculated using the cumulative probability function.
			$$
				P\text{-value} = P(H_a) = \begin{cases}
 					P(p \gtrless p_0) = P(Z \gtrless z) & H_a:p \gtrless p_0 \\
 					P(|p| < |p_0|) = P(Z < -|z|) + P(Z > |z|) & H_a:p \ne p_0
				\end{cases}
			$$
			\subsection*{Significance Tests about Differences in Proportions}
				A significance can be performed to compare the proportions for two populations is based on the difference between sample proportions.
				\begin{align*}
					H_0:p_1 - p_2 = p_0 && H_a: p_1 - p_2 \gtrless p_0 && H_a:p_1 - p_2 \ne p_0
				\end{align*}
				Typically, $p_0$ is 0, so these hypotheses can be rewritten.
				\begin{align*}
					H_0:p_1 = p_2 && H_a:p_1 \gtrless p_2 && H_a:p_1 \ne p_2
				\end{align*}
				A significance test first assumes that the null hypothesis $H_0:p_1 = p_2$ is true. This common value is referred to as $p$. \\
				The \textbf{combined sample proportion} is denoted $\hat{p}_C$ and is equal to the total successes divided by the total sample size, making it effectively a weighted average. It is the sample proportion that assumes that the parameter values are equal.
				$$\hat{p}_C = \frac{x_1 + x_2}{n_1 + n_2} = \frac{n_1\hat{p}_1 + n_2\hat{p}_2}{n_1 + n_2}$$
				The Large Counts condition must be met with $\hat{p}_C$.
				$$n_1\hat{p}_C, n_1(1 - \hat{p}_C), n_2\hat{p}_C, n_2(1 - \hat{p}_C) \ge 10$$
				\callout{17}{For a significance test to be run about a difference of proportions, the randomness, independence (10\%) (for each proportion), and Large Counts conditions must be met.}
				The standardized test statistic is the $z$ score, using the difference in proportions and its standard error assuming the mean to be 0 ($H_0$ to be true).
				$$z = \z{\hat{p}_1 - \hat{p}_2}{\mu_{\hat{p}_1 - \hat{p}_2}}{s_{\hat{p}_1 - \hat{p}_2}} = \z{\hat{p}_1 - \hat{p}_2}{0}{\propsed{\hat{p}_C}{n_1}{\hat{p}_C}{n_2}} = \z{\hat{p}_1}{\hat{p}_2}{\propsee{\hat{p}_C}{n_1}{n_2}}$$
		\section*{Significance Tests about Means}
	\chapter{Chi-Square Tests}
	\chapter{Slopes}
\end{document} 